
# modification to Gradient Descent to run on large data

Example:
## Linear regression with gradient descent:
Batch gradient descent - batch all training sample together 
-- This needs to look at all data at once
-- Each iteration get one step closer to optimal Jmin(theta)

## Stochastic Gradient descent:
1. Randomly shuffle dataset
2. Repeat 1-10 times; for i = 1,2,...,m {theta(j):= ............}

